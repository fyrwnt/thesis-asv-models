{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T07:39:28.373226Z",
     "iopub.status.busy": "2025-03-05T07:39:28.372701Z",
     "iopub.status.idle": "2025-03-05T07:39:28.389345Z",
     "shell.execute_reply": "2025-03-05T07:39:28.388257Z",
     "shell.execute_reply.started": "2025-03-05T07:39:28.373182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import concurrent.futures\n",
    "\n",
    "# Fungsi untuk padding atau truncating fitur\n",
    "def pad_or_truncate(feature, max_frames):\n",
    "    \"\"\"\n",
    "    Padding atau truncating fitur untuk memastikan panjang yang konsisten.\n",
    "    \"\"\"\n",
    "    # Jika panjang fitur kurang dari max_frames, lakukan padding\n",
    "    if feature.shape[1] < max_frames:\n",
    "        pad_width = max_frames - feature.shape[1]\n",
    "        feature = np.pad(feature, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    # Jika panjang fitur lebih dari max_frames, lakukan truncating\n",
    "    elif feature.shape[1] > max_frames:\n",
    "        feature = feature[:, :max_frames]\n",
    "    return feature\n",
    "\n",
    "# Fungsi ekstraksi Log-Mel Spectrogram\n",
    "def extract_logmel(audio_path, n_mels=13, duration=5, max_frames=250):\n",
    "    \"\"\"\n",
    "    Ekstraksi Log-Mel Spectrogram dengan padding atau truncating.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=16000, duration=duration)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=n_mels, n_fft=2048, hop_length=512)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    \n",
    "    # Lakukan padding atau truncating\n",
    "    mel_db = pad_or_truncate(mel_db, max_frames)\n",
    "    \n",
    "    return mel_db\n",
    "\n",
    "# Fungsi ekstraksi MFCC\n",
    "def extract_mfcc_40(audio_path, n_mfcc = 40, duration = 3, max_frames = 100):\n",
    "    \"\"\"\n",
    "    Ekstraksi MFCC dengan padding atau truncating.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, duration=duration, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=16000, n_mfcc=n_mfcc, n_fft=2048, hop_length=512)\n",
    "    \n",
    "    # Lakukan padding atau truncating\n",
    "    mfcc = pad_or_truncate(mfcc, max_frames)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "def extract_mfcc_13(audio_path, n_mfcc = 13, duration = 3, max_frames = 100):\n",
    "    \"\"\"\n",
    "    Ekstraksi MFCC dengan padding atau truncating.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, duration=duration, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=16000, n_mfcc=n_mfcc, n_fft=2048, hop_length=512)\n",
    "    \n",
    "    # Lakukan padding atau truncating\n",
    "    mfcc = pad_or_truncate(mfcc, max_frames)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "def load_protocol_file(protocol_file):\n",
    "    labels = {}\n",
    "    with open(protocol_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        file_name = parts[1]\n",
    "        label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "        labels[file_name] = label\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_protocol_file_com(protocol_file, categories=['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19']):\n",
    "    labels = {}\n",
    "    with open(protocol_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        file_name = parts[1]\n",
    "        \n",
    "        # Ambil jika mengandung salah satu kategori dalam nama file atau jika label \"bonafide\"\n",
    "        if any(category in line for category in categories) or parts[-1] == \"bonafide\":\n",
    "            label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "            labels[file_name] = label\n",
    "    \n",
    "    return labels\n",
    "    \n",
    "# Define the process_file function\n",
    "def process_file(file_name, label, audio_dir, feature_extractor):\n",
    "    \"\"\"\n",
    "    Process a single audio file to extract features using the given feature extractor.\n",
    "    \"\"\"\n",
    "    audio_file = os.path.join(audio_dir, file_name + '.flac')\n",
    "    if os.path.exists(audio_file):\n",
    "        features = feature_extractor(audio_file)\n",
    "        return features, label\n",
    "    return None, None\n",
    "\n",
    "# Update the load_audio_data_parallel function\n",
    "def load_audio_data_parallel(labels, audio_dir, feature_extractor):\n",
    "    \"\"\"\n",
    "    Load audio data in parallel, extracting features using the specified feature extractor.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Use ThreadPoolExecutor to process files in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for file_name, label in labels.items():\n",
    "            futures.append(executor.submit(process_file, file_name, label, audio_dir, feature_extractor))\n",
    "\n",
    "        # Collect results\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            features, label = future.result()\n",
    "            if features is not None:\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X, dtype=object)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Ensure that X is a 2D array (samples, features)\n",
    "    if X.ndim == 1:\n",
    "        X = np.vstack(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T07:39:28.391533Z",
     "iopub.status.busy": "2025-03-05T07:39:28.391200Z",
     "iopub.status.idle": "2025-03-05T07:39:28.768217Z",
     "shell.execute_reply": "2025-03-05T07:39:28.767498Z",
     "shell.execute_reply.started": "2025-03-05T07:39:28.391500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Buat tau flacnya itu spoof atau bonafide\n",
    "train_labels_wo_swf = load_protocol_file_com('/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt', categories=['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16','A18','A19'])\n",
    "dev_labels_wo_swf = load_protocol_file_com('/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt', categories=['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16','A18','A19'])\n",
    "eval_labels_wo_swf = load_protocol_file_com('/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt', categories=['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16','A18','A19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T07:39:28.769370Z",
     "iopub.status.busy": "2025-03-05T07:39:28.769153Z",
     "iopub.status.idle": "2025-03-05T08:09:03.543104Z",
     "shell.execute_reply": "2025-03-05T08:09:03.542004Z",
     "shell.execute_reply.started": "2025-03-05T07:39:28.769352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Melakukan X->flacnya dilakuin log mel spectogram, y nya label 1, 0\n",
    "X_train_mfcc_wo_swf, y_train_mfcc_wo_swf = load_audio_data_parallel(train_labels_wo_swf, '/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac', extract_mfcc_13)\n",
    "X_dev_mfcc_wo_swf, y_dev_mfcc_wo_swf = load_audio_data_parallel(dev_labels_wo_swf, '/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/flac', extract_mfcc_13)\n",
    "X_eval_mfcc_wo_swf, y_eval_mfcc_wo_swf = load_audio_data_parallel(eval_labels_wo_swf, '/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/flac', extract_mfcc_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T08:09:03.544854Z",
     "iopub.status.busy": "2025-03-05T08:09:03.544198Z",
     "iopub.status.idle": "2025-03-05T08:09:09.912294Z",
     "shell.execute_reply": "2025-03-05T08:09:09.911639Z",
     "shell.execute_reply.started": "2025-03-05T08:09:03.544820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_data(file_name, data):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# Menyimpan data X_train dan y_train\n",
    "save_data('X_train_mfcc_wo_wf_13.pkl', X_train_mfcc_wo_swf)\n",
    "save_data('y_train_mfcc_wo_wf_13.pkl', y_train_mfcc_wo_swf)\n",
    "save_data('X_dev_mfcc_wo_wf_13.pkl', X_dev_mfcc_wo_swf)\n",
    "save_data('y_dev_mfcc_wo_wf_13.pkl', y_dev_mfcc_wo_swf)\n",
    "save_data('X_eval_mfcc_wo_wf_13.pkl', X_eval_mfcc_wo_swf)\n",
    "save_data('y_eval_mfcc_wo_wf_13.pkl', y_eval_mfcc_wo_swf)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2286778,
     "sourceId": 3842332,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
